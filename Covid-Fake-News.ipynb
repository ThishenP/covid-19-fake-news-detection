{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "659902f1-83fb-48a6-a872-554e71f93735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7080bd-9360-46ee-9ae7-24f3aaae8c24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(y_pred, y_true, title=None):\n",
    "    \"\"\"Helper Function to plot confustion matrix\"\"\"\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_pred, y_true)\n",
    "    df_cm = pd.DataFrame(conf_mat, index = [i for i in [\"Fake\", \"Real\"]],\n",
    "                  columns = [i for i in [\"Fake\", \"Real\"]])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    if title:\n",
    "        plt.title(f\"{title} Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266b5af-4823-41b0-97ce-d467abb1dbae",
   "metadata": {},
   "source": [
    "# Read in Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ec800a-a3b4-465e-9b74-64d29b0ceafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_news_df = pd.read_csv(\"COVID19-FNIR/COVID19-FNIR/trueNews.csv\")\n",
    "fake_news_df = pd.read_csv(\"COVID19-FNIR/COVID19-FNIR/fakeNews.csv\")\n",
    "# Assign class columns and combine dataframes\n",
    "fake_news_df[\"class\"] = 0\n",
    "true_news_df[\"class\"] = 1\n",
    "combined = pd.concat([fake_news_df, true_news_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f7342a-bbac-46cf-8261-ae7115916a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7588, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2741c91f-efb4-4fac-bf06-7dff8abd4acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3795, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739507be-1d3e-4241-8751-172d93fd769c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3793, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358c39f1-67fc-4981-b2db-39319c965914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to just contain the text field and the class field\n",
    "combined = combined[[\"Text\", \"class\"]].reset_index(drop=True)\n",
    "# Shuffle data\n",
    "combined = combined.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec2f6f3-859f-424d-a65d-79a3440993ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Text'] = combined['Text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "combined['Text'] = combined['Text'].str.replace('pic\\S+|twitter.\\S+', '', case=False)\n",
    "combined['Text'] = combined['Text'].str.replace('#\\S+', '', case=False)\n",
    "combined['Text'] = combined['Text'].str.replace('@\\S+', '', case=False)\n",
    "combined['Text'] = combined['Text'].str.replace('Link:\\S+', '', case=False)\n",
    "combined['Text'] = combined['Text'].str.replace('[ \\t]+$', '', case=False)\n",
    "# remove front and ending blank spaces\n",
    "combined = combined.replace({\"^\\s*|\\s*$\":\"\"}, regex=True) \n",
    "\n",
    "def wordopt(text):\n",
    "    \"\"\"Formating of the text field \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) \n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)    \n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "combined[\"Text\"] = combined[\"Text\"].apply(wordopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d2a28d-7dee-4174-b055-ce8d3a22a366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new covid cases in new york coming from people leaving home cuomo'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined[\"class\"]==1].iloc[2][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485771a-1846-4ee8-8b6f-63f4593a6420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0148108e-d38e-4b59-b9c9-32346b2696eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     print(f\"{i}: {combined[combined['class']==0].iloc[i]['Text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "250e1445-9afa-4243-bd52-173849e4781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cdc now says that the coronavirus can survive on surfaces for up to days '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined[\"class\"]==0].iloc[540][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b37be7d-6983-40e0-a462-0d2f3a1be9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'follow this link to download the pandemic notebook a handy guide from the hindu on understanding the and staying protected against covid '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined[\"class\"]==1].iloc[540][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8588e879-92d7-464a-8342-5071b22b829c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>a monkey has been infected with coronavirus in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>perspective will police enforce covid stay hom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>who says looking into reports of some covid pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>new covid cases in new york coming from people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>the indian is expected to contract by in this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  class\n",
       "148   a monkey has been infected with coronavirus in...      0\n",
       "6834  perspective will police enforce covid stay hom...      1\n",
       "4887  who says looking into reports of some covid pa...      1\n",
       "6283  new covid cases in new york coming from people...      1\n",
       "6959  the indian is expected to contract by in this ...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd7e42c6-72c4-4ee3-9fb2-0ede20e16110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y variables\n",
    "X = combined[\"Text\"]\n",
    "y = combined[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c8b19fc-1a66-4d25-81b9-52457bcd9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61573d3c-af7a-4d5e-adce-2db063ed1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html \n",
    "\n",
    "vectorization = TfidfVectorizer()\n",
    "X_train = vectorization.fit_transform(X_train)\n",
    "X_test = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac59ee7-3e2e-4189-a87e-f4b88a413acb",
   "metadata": {},
   "source": [
    "# Model 1: Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0d7a940-75b1-4c7d-a9bd-3c647e87f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "# Fit model \n",
    "nb_model.fit(X_train, y_train)\n",
    "# Predict \n",
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "262ad684-5594-4d6f-a163-3770d6882698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8961518186610438\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b01575a4-f621-4efd-8810-5b11ef7b2992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       933\n",
      "           1       0.90      0.89      0.90       964\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.90      0.90      0.90      1897\n",
      "weighted avg       0.90      0.90      0.90      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f0fff98-4b50-4515-8afe-29a65346b6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(y_pred, y_test, title=\"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6766beb6-fb12-4792-b9e7-cbf94a6b43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "params = {\n",
    "    \"alpha\": [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1.0, 1.5, 2, 3, 5, 10],\n",
    "    \"fit_prior\": (True, False),\n",
    "}\n",
    "gs_clf = GridSearchCV(MultinomialNB(), params, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdee0b08-131d-4f5a-9e53-2e80e16c0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88ce76af-295f-4742-b7da-62ee92257730",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a75c77b0-4da1-479a-b10e-d363e7c8de38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8634686346863468\n",
      "Test Precision: 0.8528528528528528\n",
      "Test Recall: 0.8838174273858921\n",
      "Test f1 Score: 0.8680590932246562\n",
      "Test roc auc score: 0.8631305786447145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Test f1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Test roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5cd04a36-62a9-47e3-a4cc-5010578710b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       933\n",
      "           1       0.85      0.88      0.87       964\n",
      "\n",
      "    accuracy                           0.86      1897\n",
      "   macro avg       0.86      0.86      0.86      1897\n",
      "weighted avg       0.86      0.86      0.86      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "317ebf93-58bb-4fad-b283-43980c628a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(y_pred, y_test, title=\"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e77592-c6e4-4a9c-845a-2f0cff3cf99e",
   "metadata": {},
   "source": [
    "# Model 2: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df52e268-b8ff-4ee4-85aa-cb82c4e51bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbt_model = GradientBoostingClassifier()\n",
    "# Fit model \n",
    "gbt_model.fit(X_train, y_train)\n",
    "# Predict \n",
    "y_pred = gbt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d11cb9d9-4976-455e-b458-6adfc66778cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.863995782814971\n",
      "Test Precision: 0.8537074148296593\n",
      "Test Recall: 0.8838174273858921\n",
      "Test f1 Score: 0.8685015290519876\n",
      "Test roc auc score: 0.8636664843253147\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Test f1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Test roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2749b4ef-aed6-4bc7-bf0c-4b3a447a9ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       933\n",
      "           1       0.85      0.88      0.87       964\n",
      "\n",
      "    accuracy                           0.86      1897\n",
      "   macro avg       0.86      0.86      0.86      1897\n",
      "weighted avg       0.86      0.86      0.86      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f4da19d-82b8-4823-aa00-d6e4eb030c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(y_pred, y_test, title=\"Gradient Boosting Classifier Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b6d842e-fadb-4844-b25e-74dcb5552717",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV 2/5; 2/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 2/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75;, score=0.836 total time=   0.4s\n",
      "[CV 2/5; 4/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 4/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5;, score=0.835 total time=   1.6s\n",
      "[CV 4/5; 6/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 6/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0;, score=0.804 total time=   2.6s\n",
      "[CV 1/5; 9/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 9/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0;, score=0.831 total time=   6.0s\n",
      "[CV 5/5; 11/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 5/5; 11/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75;, score=0.834 total time=  23.4s\n",
      "[CV 1/5; 19/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 19/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5;, score=0.830 total time=   3.1s\n",
      "[CV 3/5; 20/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 3/5; 20/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75;, score=0.828 total time=   5.4s\n",
      "[CV 2/5; 22/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 2/5; 22/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.5;, score=0.837 total time=  17.6s\n",
      "[CV 3/5; 24/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 3/5; 24/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=1.0;, score=0.827 total time=  24.9s\n",
      "[CV 4/5; 34/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 34/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5;, score=0.823 total time=  17.2s\n",
      "[CV 1/5; 37/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 1/5; 37/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5;, score=0.830 total time=   0.4s\n",
      "[CV 2/5; 37/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 37/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5;, score=0.832 total time=   0.3s\n",
      "[CV 3/5; 37/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 37/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5;, score=0.828 total time=   0.4s\n",
      "[CV 5/5; 37/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 5/5; 37/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5;, score=0.829 total time=   0.3s\n",
      "[CV 2/5; 38/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 38/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75;, score=0.833 total time=   0.4s\n",
      "[CV 4/5; 38/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 38/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75;, score=0.804 total time=   0.4s\n",
      "[CV 1/5; 39/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 39/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0;, score=0.831 total time=   0.5s\n",
      "[CV 3/5; 39/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 39/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0;, score=0.827 total time=   0.4s\n",
      "[CV 5/5; 39/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 39/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.5s\n",
      "[CV 2/5; 40/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 40/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5;, score=0.834 total time=   1.8s\n",
      "[CV 4/5; 40/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 40/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5;, score=0.806 total time=   1.6s\n",
      "[CV 3/5; 41/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 3/5; 41/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75;, score=0.830 total time=   1.8s\n",
      "[CV 4/5; 42/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 42/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0;, score=0.805 total time=   2.4s\n",
      "[CV 1/5; 44/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 44/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.75;, score=0.827 total time=   4.9s\n",
      "[CV 5/5; 45/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 45/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0;, score=0.830 total time=   5.4s\n",
      "[CV 4/5; 47/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 47/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75;, score=0.819 total time=  24.5s\n",
      "[CV 4/5; 54/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 54/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.825 total time=   2.3s\n",
      "[CV 5/5; 55/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 55/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.875 total time=   3.7s\n",
      "[CV 3/5; 57/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 57/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.862 total time=   5.2s\n",
      "[CV 5/5; 58/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 58/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.901 total time=  16.0s\n",
      "[CV 4/5; 61/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 61/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.809 total time=   0.3s\n",
      "[CV 1/5; 62/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 62/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.828 total time=   0.5s\n",
      "[CV 3/5; 62/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 62/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.828 total time=   0.4s\n",
      "[CV 5/5; 62/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 62/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.824 total time=   0.5s\n",
      "[CV 2/5; 63/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 63/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.827 total time=   0.5s\n",
      "[CV 4/5; 63/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 63/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.808 total time=   0.5s\n",
      "[CV 1/5; 64/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 64/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.853 total time=   1.6s\n",
      "[CV 3/5; 64/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 3/5; 64/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.836 total time=   1.9s\n",
      "[CV 3/5; 65/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75[CV 4/5; 1/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 1/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.5;, score=0.811 total time=   0.4s\n",
      "[CV 1/5; 4/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 4/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5;, score=0.831 total time=   1.8s\n",
      "[CV 5/5; 6/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 6/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0;, score=0.830 total time=   3.3s\n",
      "[CV 2/5; 9/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 9/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0;, score=0.831 total time=   4.7s\n",
      "[CV 3/5; 11/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 11/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75;, score=0.828 total time=  21.8s\n",
      "[CV 5/5; 17/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 5/5; 17/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75;, score=0.833 total time=   2.0s\n",
      "[CV 5/5; 18/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 18/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0;, score=0.830 total time=   2.6s\n",
      "[CV 5/5; 19/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 19/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5;, score=0.828 total time=   3.2s\n",
      "[CV 2/5; 21/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 21/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0;, score=0.831 total time=   6.8s\n",
      "[CV 1/5; 23/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 1/5; 23/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75;, score=0.831 total time=  25.1s\n",
      "[CV 1/5; 30/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 30/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0;, score=0.831 total time=   2.6s\n",
      "[CV 2/5; 31/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 31/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5;, score=0.841 total time=   3.6s\n",
      "[CV 3/5; 32/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 3/5; 32/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75;, score=0.827 total time=   4.0s\n",
      "[CV 1/5; 34/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 1/5; 34/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5;, score=0.859 total time=  17.6s\n",
      "[CV 3/5; 36/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 3/5; 36/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0;, score=0.845 total time=  26.5s\n",
      "[CV 5/5; 47/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 5/5; 47/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75;, score=0.854 total time=  23.2s\n",
      "[CV 2/5; 55/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 55/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.863 total time=   3.4s\n",
      "[CV 4/5; 56/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 4/5; 56/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.830 total time=   5.6s\n",
      "[CV 3/5; 58/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 3/5; 58/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.880 total time=  16.9s\n",
      "[CV 1/5; 61/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 1/5; 61/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.824 total time=   0.3s\n",
      "[CV 2/5; 61/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 61/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.834 total time=   0.3s\n",
      "[CV 3/5; 61/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 61/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.826 total time=   0.3s\n",
      "[CV 5/5; 61/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 5/5; 61/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.830 total time=   0.4s\n",
      "[CV 2/5; 62/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 62/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.829 total time=   0.5s\n",
      "[CV 4/5; 62/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 62/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.808 total time=   0.5s\n",
      "[CV 1/5; 63/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 63/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.831 total time=   0.6s\n",
      "[CV 3/5; 63/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 63/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.828 total time=   0.6s\n",
      "[CV 5/5; 63/120] START learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 63/120] END learning_rate=0.1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.7s\n",
      "[CV 2/5; 64/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 64/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.843 total time=   1.6s\n",
      "[CV 5/5; 64/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 5/5; 64/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.849 total time=   1.7s\n",
      "[CV 4/5; 65/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 4/5; 65/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75;, score=0.820 total time=   2.0s\n",
      "[CV 5/5; 66/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 66/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.857 total time=   2.2s\n",
      "[CV 5/5; 67/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 67/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.866 total time=   3.2s\n",
      "[CV 3/5; 69/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 69/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.860 total time=   5.0s\n",
      "[CV 5/5; 70/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 70/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5;, score=0.895 total time=  15.5s\n",
      "[CV 3/5; 74/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 74/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.859 total time=   0.5s\n",
      "[CV 5/5; 74/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 74/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.860 total time=   0.4s\n",
      "[CV 2/5; 75/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 75/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.866 total time=   0.5s\n",
      "[CV 4/5; 75/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 75/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.840 total time=   0.6s[CV 3/5; 1/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 1/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.5;, score=0.833 total time=   0.3s\n",
      "[CV 5/5; 3/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 3/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.6s\n",
      "[CV 1/5; 6/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 6/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0;, score=0.829 total time=   3.0s\n",
      "[CV 4/5; 8/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 4/5; 8/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75;, score=0.803 total time=   4.4s\n",
      "[CV 1/5; 11/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 1/5; 11/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75;, score=0.828 total time=  22.7s\n",
      "[CV 1/5; 17/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 1/5; 17/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75;, score=0.830 total time=   2.8s\n",
      "[CV 4/5; 18/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 18/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0;, score=0.804 total time=   3.0s\n",
      "[CV 2/5; 20/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 2/5; 20/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75;, score=0.832 total time=   4.8s\n",
      "[CV 5/5; 21/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 21/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0;, score=0.830 total time=   7.5s\n",
      "[CV 4/5; 23/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 23/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75;, score=0.805 total time=  24.8s\n",
      "[CV 1/5; 31/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 31/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5;, score=0.836 total time=   4.6s\n",
      "[CV 4/5; 32/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 4/5; 32/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75;, score=0.812 total time=   4.4s\n",
      "[CV 2/5; 34/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 2/5; 34/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5;, score=0.853 total time=  16.6s\n",
      "[CV 4/5; 36/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 4/5; 36/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0;, score=0.822 total time=  28.6s\n",
      "[CV 2/5; 48/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 2/5; 48/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=1.0;, score=0.850 total time=  28.4s\n",
      "[CV 5/5; 57/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 57/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.874 total time=   6.4s\n",
      "[CV 4/5; 59/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 59/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.861 total time=  20.1s\n",
      "[CV 5/5; 65/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 5/5; 65/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75;, score=0.850 total time=   2.4s\n",
      "[CV 2/5; 67/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 67/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.855 total time=   3.2s\n",
      "[CV 4/5; 68/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 4/5; 68/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75;, score=0.827 total time=   5.0s\n",
      "[CV 4/5; 70/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 70/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5;, score=0.854 total time=  14.5s\n",
      "[CV 1/5; 73/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 1/5; 73/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.843 total time=   0.3s\n",
      "[CV 2/5; 73/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 73/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.854 total time=   0.3s\n",
      "[CV 3/5; 73/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 73/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.851 total time=   0.3s\n",
      "[CV 4/5; 73/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 73/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.841 total time=   0.5s\n",
      "[CV 5/5; 73/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 5/5; 73/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.3s\n",
      "[CV 1/5; 74/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 74/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.856 total time=   0.6s\n",
      "[CV 2/5; 74/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 74/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.855 total time=   0.5s\n",
      "[CV 4/5; 74/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 74/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.834 total time=   0.5s\n",
      "[CV 1/5; 75/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 75/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.853 total time=   0.5s\n",
      "[CV 3/5; 75/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 75/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.846 total time=   0.5s\n",
      "[CV 5/5; 75/120] START learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 75/120] END learning_rate=1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.867 total time=   0.5s\n",
      "[CV 1/5; 76/120] START learning_rate=1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 76/120] END learning_rate=1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.853 total time=   1.6s\n",
      "[CV 3/5; 76/120] START learning_rate=1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 3/5; 76/120] END learning_rate=1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.848 total time=   1.6s\n",
      "[CV 5/5; 76/120] START learning_rate=1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 5/5; 76/120] END learning_rate=1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.861 total time=   1.6s\n",
      "[CV 4/5; 77/120] START learning_rate=1, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 4/5; 77/120] END learning_rate=1, loss=deviance, n_estimators=50, subsample=0.75;, score=0.837 total time=   2.7s\n",
      "[CV 5/5; 78/120] START learning_rate=1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 78/120] END learning_rate=1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.879 total time=   2.5s\n",
      "[CV 1/5; 80/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 80/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.862 total time=   3.9s\n",
      "[CV 3/5; 81/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 81/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.863 total time=   5.6s\n",
      "[CV 2/5; 83/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75[CV 4/5; 2/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 2/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75;, score=0.808 total time=   0.6s\n",
      "[CV 2/5; 6/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 6/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=1.0;, score=0.830 total time=   2.4s\n",
      "[CV 3/5; 8/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 3/5; 8/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75;, score=0.828 total time=   4.6s\n",
      "[CV 5/5; 10/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 10/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5;, score=0.830 total time=  16.4s\n",
      "[CV 4/5; 13/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 13/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5;, score=0.810 total time=   0.3s\n",
      "[CV 1/5; 14/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 14/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75;, score=0.819 total time=   0.5s\n",
      "[CV 3/5; 14/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 14/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75;, score=0.837 total time=   0.5s\n",
      "[CV 5/5; 14/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 14/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75;, score=0.836 total time=   0.5s\n",
      "[CV 2/5; 15/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 15/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.5s\n",
      "[CV 4/5; 15/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 15/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0;, score=0.808 total time=   0.5s\n",
      "[CV 1/5; 16/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 16/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5;, score=0.832 total time=   1.8s\n",
      "[CV 3/5; 16/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 3/5; 16/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5;, score=0.828 total time=   2.4s\n",
      "[CV 3/5; 17/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 3/5; 17/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75;, score=0.828 total time=   2.9s\n",
      "[CV 2/5; 19/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 19/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5;, score=0.836 total time=   4.3s\n",
      "[CV 4/5; 20/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 4/5; 20/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75;, score=0.804 total time=   5.9s\n",
      "[CV 4/5; 22/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 22/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.5;, score=0.806 total time=  17.8s\n",
      "[CV 1/5; 25/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 1/5; 25/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5;, score=0.833 total time=   0.3s\n",
      "[CV 2/5; 25/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 25/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5;, score=0.826 total time=   0.5s\n",
      "[CV 4/5; 25/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 25/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5;, score=0.806 total time=   0.3s\n",
      "[CV 1/5; 26/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 26/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75;, score=0.830 total time=   0.4s\n",
      "[CV 3/5; 26/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 26/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75;, score=0.827 total time=   0.5s\n",
      "[CV 5/5; 26/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 26/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75;, score=0.830 total time=   0.5s\n",
      "[CV 2/5; 27/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 27/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0;, score=0.831 total time=   0.5s\n",
      "[CV 4/5; 27/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 27/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0;, score=0.804 total time=   0.5s\n",
      "[CV 1/5; 28/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 28/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5;, score=0.839 total time=   1.5s\n",
      "[CV 3/5; 28/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 3/5; 28/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5;, score=0.829 total time=   1.4s\n",
      "[CV 5/5; 28/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 5/5; 28/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5;, score=0.826 total time=   1.7s\n",
      "[CV 2/5; 29/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 2/5; 29/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75;, score=0.834 total time=   2.5s\n",
      "[CV 3/5; 30/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 30/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0;, score=0.827 total time=   2.4s\n",
      "[CV 4/5; 31/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 31/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5;, score=0.808 total time=   2.9s\n",
      "[CV 5/5; 32/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 5/5; 32/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75;, score=0.830 total time=   4.4s\n",
      "[CV 3/5; 34/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 3/5; 34/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5;, score=0.845 total time=  16.9s\n",
      "[CV 5/5; 36/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 5/5; 36/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0;, score=0.856 total time=  26.2s\n",
      "[CV 1/5; 48/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 1/5; 48/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=1.0;, score=0.854 total time=  26.9s\n",
      "[CV 5/5; 56/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 5/5; 56/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.880 total time=   5.6s\n",
      "[CV 4/5; 58/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 58/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.863 total time=  15.9s\n",
      "[CV 5/5; 60/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 5/5; 60/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=1.0;, score=0.902 total time=  27.1s\n",
      "[CV 2/5; 72/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 2/5; 72/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0;, score=0.881 total time=  29.1s\n",
      "[CV 4/5; 82/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 82/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.827 total time=  15.5s[CV 2/5; 1/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 1/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.5;, score=0.833 total time=   0.3s\n",
      "[CV 3/5; 3/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 3/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0;, score=0.827 total time=   0.5s\n",
      "[CV 3/5; 5/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 3/5; 5/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75;, score=0.828 total time=   2.1s\n",
      "[CV 4/5; 7/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 7/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5;, score=0.802 total time=   2.9s\n",
      "[CV 1/5; 10/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 1/5; 10/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5;, score=0.835 total time=  14.9s\n",
      "[CV 3/5; 12/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 3/5; 12/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0;, score=0.827 total time=  30.0s\n",
      "[CV 5/5; 23/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 5/5; 23/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75;, score=0.835 total time=  25.7s\n",
      "[CV 5/5; 31/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 31/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5;, score=0.828 total time=   3.1s\n",
      "[CV 1/5; 33/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 33/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0;, score=0.836 total time=   6.1s\n",
      "[CV 1/5; 35/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 1/5; 35/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75;, score=0.858 total time=  25.6s\n",
      "[CV 3/5; 42/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 42/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0;, score=0.827 total time=   2.5s\n",
      "[CV 5/5; 43/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 43/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5;, score=0.824 total time=   3.0s\n",
      "[CV 2/5; 45/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 45/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0;, score=0.833 total time=   6.4s\n",
      "[CV 3/5; 47/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 47/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75;, score=0.844 total time=  22.1s\n",
      "[CV 2/5; 53/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 2/5; 53/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75;, score=0.856 total time=   2.4s\n",
      "[CV 2/5; 54/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 54/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.858 total time=   2.2s\n",
      "[CV 4/5; 55/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 55/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.833 total time=   3.8s\n",
      "[CV 1/5; 57/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 57/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.866 total time=   7.6s\n",
      "[CV 2/5; 59/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 2/5; 59/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.891 total time=  22.6s\n",
      "[CV 1/5; 66/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 66/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.854 total time=   3.2s\n",
      "[CV 1/5; 68/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 68/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75;, score=0.863 total time=   4.5s\n",
      "[CV 4/5; 69/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 69/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.829 total time=   4.4s\n",
      "[CV 3/5; 71/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 71/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.75;, score=0.881 total time=  23.6s\n",
      "[CV 3/5; 78/120] START learning_rate=1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 78/120] END learning_rate=1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.860 total time=   2.9s\n",
      "[CV 5/5; 79/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 79/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.838 total time=   2.7s\n",
      "[CV 1/5; 81/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 81/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.871 total time=   5.7s\n",
      "[CV 5/5; 82/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 82/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.836 total time=  15.3s\n",
      "[CV 3/5; 85/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 85/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.839 total time=   0.2s\n",
      "[CV 4/5; 85/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 85/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=0.5;, score=0.820 total time=   0.3s\n",
      "[CV 1/5; 86/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 86/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.844 total time=   0.5s\n",
      "[CV 3/5; 86/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 86/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.843 total time=   0.6s\n",
      "[CV 5/5; 86/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 86/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=0.75;, score=0.857 total time=   0.6s\n",
      "[CV 2/5; 87/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 87/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.857 total time=   0.7s\n",
      "[CV 4/5; 87/120] START learning_rate=1, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 87/120] END learning_rate=1, loss=exponential, n_estimators=10, subsample=1.0;, score=0.818 total time=   0.7s\n",
      "[CV 2/5; 88/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 88/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.856 total time=   2.1s\n",
      "[CV 4/5; 88/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 88/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.827 total time=   1.3s\n",
      "[CV 2/5; 89/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 2/5; 89/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=0.75;, score=0.860 total time=   2.1s\n",
      "[CV 3/5; 90/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 90/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.864 total time=   2.7s\n",
      "[CV 4/5; 91/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 91/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.838 total time=   3.6s[CV 5/5; 2/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 2/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75;, score=0.837 total time=   0.6s\n",
      "[CV 4/5; 5/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 4/5; 5/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75;, score=0.805 total time=   2.3s\n",
      "[CV 2/5; 8/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 2/5; 8/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75;, score=0.832 total time=   4.6s\n",
      "[CV 4/5; 10/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 10/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5;, score=0.806 total time=  15.3s\n",
      "[CV 5/5; 12/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 5/5; 12/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0;, score=0.839 total time=  34.6s\n",
      "[CV 2/5; 24/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 2/5; 24/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=1.0;, score=0.836 total time=  27.9s\n",
      "[CV 5/5; 34/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 34/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.5;, score=0.851 total time=  17.6s\n",
      "[CV 4/5; 37/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 37/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.5;, score=0.808 total time=   0.4s\n",
      "[CV 1/5; 38/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 38/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75;, score=0.824 total time=   0.5s\n",
      "[CV 3/5; 38/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 38/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75;, score=0.828 total time=   0.3s\n",
      "[CV 5/5; 38/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 38/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=0.75;, score=0.833 total time=   0.4s\n",
      "[CV 2/5; 39/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 39/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0;, score=0.831 total time=   0.5s\n",
      "[CV 4/5; 39/120] START learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 39/120] END learning_rate=0.01, loss=exponential, n_estimators=10, subsample=1.0;, score=0.804 total time=   0.8s\n",
      "[CV 1/5; 40/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 40/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5;, score=0.834 total time=   2.0s\n",
      "[CV 5/5; 40/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 5/5; 40/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5;, score=0.830 total time=   1.7s\n",
      "[CV 4/5; 41/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 4/5; 41/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75;, score=0.808 total time=   2.4s\n",
      "[CV 1/5; 43/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 43/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5;, score=0.831 total time=   4.1s\n",
      "[CV 5/5; 44/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 5/5; 44/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.75;, score=0.825 total time=   4.8s\n",
      "[CV 4/5; 46/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 46/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.5;, score=0.822 total time=  16.8s\n",
      "[CV 2/5; 49/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 49/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.835 total time=   0.4s\n",
      "[CV 5/5; 49/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 5/5; 49/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.844 total time=   0.3s\n",
      "[CV 2/5; 50/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 50/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.837 total time=   0.4s\n",
      "[CV 4/5; 50/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 50/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.815 total time=   0.4s\n",
      "[CV 5/5; 50/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 5/5; 50/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.828 total time=   0.5s\n",
      "[CV 2/5; 51/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 51/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.842 total time=   0.6s\n",
      "[CV 4/5; 51/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 4/5; 51/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.812 total time=   0.7s\n",
      "[CV 2/5; 52/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 52/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.849 total time=   1.8s\n",
      "[CV 4/5; 52/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 52/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.821 total time=   2.5s\n",
      "[CV 3/5; 53/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 3/5; 53/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75;, score=0.847 total time=   2.6s\n",
      "[CV 5/5; 54/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 54/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.853 total time=   3.2s\n",
      "[CV 2/5; 56/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 2/5; 56/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.866 total time=   5.2s\n",
      "[CV 1/5; 58/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 1/5; 58/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.878 total time=  17.1s\n",
      "[CV 4/5; 60/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 4/5; 60/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=1.0;, score=0.852 total time=  27.4s\n",
      "[CV 1/5; 72/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 1/5; 72/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0;, score=0.879 total time=  26.8s\n",
      "[CV 4/5; 81/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 81/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.846 total time=   5.2s\n",
      "[CV 4/5; 83/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 83/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.839 total time=  23.6s\n",
      "[CV 4/5; 90/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 90/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.839 total time=   2.5s\n",
      "[CV 5/5; 91/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 91/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.862 total time=   3.4s\n",
      "[CV 5/5; 92/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 5/5; 92/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=0.75;, score=0.881 total time=   4.9s[CV 1/5; 2/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 2/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75;, score=0.831 total time=   0.5s\n",
      "[CV 5/5; 5/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 5/5; 5/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75;, score=0.831 total time=   2.1s\n",
      "[CV 1/5; 8/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 8/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.75;, score=0.832 total time=   4.5s\n",
      "[CV 3/5; 10/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 3/5; 10/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5;, score=0.827 total time=  16.3s\n",
      "[CV 1/5; 13/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 1/5; 13/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5;, score=0.824 total time=   0.3s\n",
      "[CV 2/5; 13/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 2/5; 13/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5;, score=0.832 total time=   0.3s\n",
      "[CV 3/5; 13/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 13/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5;, score=0.835 total time=   0.3s\n",
      "[CV 5/5; 13/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5\n",
      "[CV 5/5; 13/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.5;, score=0.815 total time=   0.3s\n",
      "[CV 2/5; 14/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 14/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75;, score=0.830 total time=   0.6s\n",
      "[CV 4/5; 14/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 14/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=0.75;, score=0.813 total time=   0.4s\n",
      "[CV 1/5; 15/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 15/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0;, score=0.829 total time=   0.5s\n",
      "[CV 3/5; 15/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 15/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0;, score=0.827 total time=   0.5s\n",
      "[CV 5/5; 15/120] START learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 15/120] END learning_rate=0.001, loss=exponential, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.5s\n",
      "[CV 2/5; 16/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 16/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5;, score=0.835 total time=   2.2s\n",
      "[CV 4/5; 16/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 16/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.5;, score=0.802 total time=   1.4s\n",
      "[CV 2/5; 17/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 2/5; 17/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=0.75;, score=0.830 total time=   2.2s\n",
      "[CV 1/5; 18/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 18/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0;, score=0.829 total time=   2.9s\n",
      "[CV 3/5; 19/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 19/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.5;, score=0.829 total time=   3.9s\n",
      "[CV 3/5; 21/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 21/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0;, score=0.827 total time=   7.1s\n",
      "[CV 2/5; 23/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 2/5; 23/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75;, score=0.836 total time=  23.6s\n",
      "[CV 3/5; 29/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 3/5; 29/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75;, score=0.829 total time=   2.0s\n",
      "[CV 2/5; 30/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 30/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0;, score=0.839 total time=   2.5s\n",
      "[CV 3/5; 31/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 31/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.5;, score=0.830 total time=   4.2s\n",
      "[CV 2/5; 33/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 33/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0;, score=0.836 total time=   5.8s\n",
      "[CV 2/5; 35/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 2/5; 35/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75;, score=0.857 total time=  24.3s\n",
      "[CV 5/5; 41/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 5/5; 41/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75;, score=0.835 total time=   2.8s\n",
      "[CV 2/5; 43/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 43/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5;, score=0.837 total time=   3.1s\n",
      "[CV 4/5; 44/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 4/5; 44/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.75;, score=0.809 total time=   4.3s\n",
      "[CV 2/5; 46/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 2/5; 46/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.5;, score=0.847 total time=  16.1s\n",
      "[CV 4/5; 48/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 4/5; 48/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=1.0;, score=0.822 total time=  27.2s\n",
      "[CV 5/5; 59/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 5/5; 59/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.902 total time=  21.6s\n",
      "[CV 1/5; 67/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 67/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.862 total time=   3.1s\n",
      "[CV 3/5; 68/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 3/5; 68/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75;, score=0.858 total time=   4.5s\n",
      "[CV 1/5; 70/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 1/5; 70/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5;, score=0.876 total time=  15.4s\n",
      "[CV 4/5; 72/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 4/5; 72/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0;, score=0.852 total time=  27.5s\n",
      "[CV 2/5; 84/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 2/5; 84/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=1.0;, score=0.886 total time=  27.3s\n",
      "[CV 2/5; 93/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 93/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.880 total time=   5.0s\n",
      "[CV 5/5; 94/120] START learning_rate=1, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 94/120] END learning_rate=1, loss=exponential, n_estimators=500, subsample=0.5;, score=0.887 total time=  15.4s\n",
      "[CV 1/5; 97/120] START learning_rate=2, loss=deviance, n_estimators=10, subsample=0.5[CV 2/5; 3/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 2/5; 3/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.5s\n",
      "[CV 2/5; 5/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 2/5; 5/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.75;, score=0.830 total time=   2.0s\n",
      "[CV 3/5; 7/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 7/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5;, score=0.829 total time=   3.4s\n",
      "[CV 2/5; 10/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 2/5; 10/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.5;, score=0.835 total time=  16.2s\n",
      "[CV 4/5; 12/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 4/5; 12/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0;, score=0.808 total time=  28.9s\n",
      "[CV 1/5; 24/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 1/5; 24/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=1.0;, score=0.832 total time=  30.0s\n",
      "[CV 3/5; 33/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 33/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0;, score=0.829 total time=   5.5s\n",
      "[CV 3/5; 35/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 35/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75;, score=0.847 total time=  20.0s\n",
      "[CV 3/5; 40/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 3/5; 40/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.5;, score=0.828 total time=   1.6s\n",
      "[CV 1/5; 41/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 1/5; 41/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=0.75;, score=0.830 total time=   2.3s\n",
      "[CV 1/5; 42/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 42/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0;, score=0.832 total time=   2.5s\n",
      "[CV 3/5; 43/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 43/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5;, score=0.830 total time=   3.4s\n",
      "[CV 1/5; 45/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 45/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0;, score=0.825 total time=   5.5s\n",
      "[CV 5/5; 46/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 46/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.5;, score=0.848 total time=  15.7s\n",
      "[CV 1/5; 49/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 1/5; 49/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.834 total time=   0.3s\n",
      "[CV 3/5; 49/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 49/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.830 total time=   0.3s\n",
      "[CV 4/5; 49/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 4/5; 49/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.5;, score=0.812 total time=   0.3s\n",
      "[CV 1/5; 50/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 1/5; 50/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.831 total time=   0.4s\n",
      "[CV 3/5; 50/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 50/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=0.75;, score=0.830 total time=   0.5s\n",
      "[CV 1/5; 51/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 51/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.832 total time=   0.5s\n",
      "[CV 3/5; 51/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 51/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.6s\n",
      "[CV 5/5; 51/120] START learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 51/120] END learning_rate=0.1, loss=deviance, n_estimators=10, subsample=1.0;, score=0.829 total time=   0.4s\n",
      "[CV 1/5; 52/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 1/5; 52/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.854 total time=   1.3s\n",
      "[CV 3/5; 52/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 3/5; 52/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.848 total time=   2.0s\n",
      "[CV 5/5; 52/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 5/5; 52/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.5;, score=0.862 total time=   1.7s\n",
      "[CV 4/5; 53/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 4/5; 53/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75;, score=0.825 total time=   1.9s\n",
      "[CV 3/5; 54/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 54/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.849 total time=   2.7s\n",
      "[CV 1/5; 56/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 56/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.867 total time=   4.6s\n",
      "[CV 4/5; 57/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 57/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.836 total time=   6.4s\n",
      "[CV 3/5; 59/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 59/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.879 total time=  20.2s\n",
      "[CV 2/5; 65/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 2/5; 65/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75;, score=0.849 total time=   2.0s\n",
      "[CV 3/5; 66/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 66/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.844 total time=   2.4s\n",
      "[CV 4/5; 67/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 67/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.825 total time=   2.7s\n",
      "[CV 1/5; 69/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 69/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.861 total time=   4.4s\n",
      "[CV 3/5; 70/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 3/5; 70/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5;, score=0.875 total time=  14.3s\n",
      "[CV 5/5; 72/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 5/5; 72/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0;, score=0.904 total time=  27.0s\n",
      "[CV 1/5; 84/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 1/5; 84/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=1.0;, score=0.879 total time=  27.9s\n",
      "[CV 4/5; 93/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 93/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.851 total time=   5.3s\n",
      "[CV 1/5; 95/120] START learning_rate=1, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 1/5; 95/120] END learning_rate=1, loss=exponential, n_estimators=500, subsample=0.75;, score=0.888 total time=  23.5s[CV 3/5; 2/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 3/5; 2/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=0.75;, score=0.835 total time=   0.4s\n",
      "[CV 4/5; 4/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 4/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5;, score=0.803 total time=   1.6s\n",
      "[CV 1/5; 7/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 7/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5;, score=0.825 total time=   3.4s\n",
      "[CV 3/5; 9/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 9/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0;, score=0.827 total time=   5.8s\n",
      "[CV 2/5; 12/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 2/5; 12/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=1.0;, score=0.836 total time=  28.2s\n",
      "[CV 1/5; 21/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 21/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0;, score=0.831 total time=   5.4s\n",
      "[CV 5/5; 22/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 22/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.5;, score=0.829 total time=  18.3s\n",
      "[CV 3/5; 25/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 3/5; 25/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5;, score=0.826 total time=   0.3s\n",
      "[CV 5/5; 25/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5\n",
      "[CV 5/5; 25/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.5;, score=0.830 total time=   0.3s\n",
      "[CV 2/5; 26/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 2/5; 26/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75;, score=0.832 total time=   0.4s\n",
      "[CV 4/5; 26/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75\n",
      "[CV 4/5; 26/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=0.75;, score=0.806 total time=   0.4s\n",
      "[CV 1/5; 27/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 27/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0;, score=0.831 total time=   0.5s\n",
      "[CV 3/5; 27/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 3/5; 27/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0;, score=0.827 total time=   0.5s\n",
      "[CV 5/5; 27/120] START learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 5/5; 27/120] END learning_rate=0.01, loss=deviance, n_estimators=10, subsample=1.0;, score=0.830 total time=   0.5s\n",
      "[CV 2/5; 28/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 2/5; 28/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5;, score=0.833 total time=   1.5s\n",
      "[CV 4/5; 28/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 28/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.5;, score=0.807 total time=   1.6s\n",
      "[CV 1/5; 29/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 1/5; 29/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75;, score=0.828 total time=   2.0s\n",
      "[CV 4/5; 29/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 4/5; 29/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75;, score=0.803 total time=   2.5s\n",
      "[CV 5/5; 30/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 30/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0;, score=0.840 total time=   3.1s\n",
      "[CV 2/5; 32/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 2/5; 32/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75;, score=0.840 total time=   4.7s\n",
      "[CV 5/5; 33/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 33/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0;, score=0.830 total time=   6.7s\n",
      "[CV 2/5; 36/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 2/5; 36/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=1.0;, score=0.857 total time=  28.1s\n",
      "[CV 3/5; 45/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 45/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0;, score=0.828 total time=   5.5s\n",
      "[CV 1/5; 47/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 1/5; 47/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75;, score=0.853 total time=  24.3s\n",
      "[CV 5/5; 53/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 5/5; 53/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75;, score=0.860 total time=   2.0s\n",
      "[CV 1/5; 55/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 55/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.866 total time=   3.2s\n",
      "[CV 3/5; 56/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 3/5; 56/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.857 total time=   5.2s\n",
      "[CV 2/5; 58/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 2/5; 58/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.5;, score=0.890 total time=  16.3s\n",
      "[CV 3/5; 60/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=1.0\n",
      "[CV 3/5; 60/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=1.0;, score=0.879 total time=  25.2s\n",
      "[CV 4/5; 71/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 71/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.75;, score=0.859 total time=  22.8s\n",
      "[CV 1/5; 79/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 79/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.843 total time=   2.8s\n",
      "[CV 3/5; 80/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 3/5; 80/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=0.75;, score=0.859 total time=   4.0s\n",
      "[CV 5/5; 81/120] START learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 81/120] END learning_rate=1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.873 total time=   4.9s\n",
      "[CV 3/5; 83/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 83/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.862 total time=  21.2s\n",
      "[CV 3/5; 89/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 3/5; 89/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=0.75;, score=0.859 total time=   2.5s\n",
      "[CV 5/5; 90/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 90/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.873 total time=   3.1s\n",
      "[CV 2/5; 92/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 2/5; 92/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=0.75;, score=0.880 total time=   4.1s\n",
      "[CV 5/5; 93/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 93/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.874 total time=   4.7s\n",
      "[CV 4/5; 95/120] START learning_rate=1, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 95/120] END learning_rate=1, loss=exponential, n_estimators=500, subsample=0.75;, score=0.866 total time=  23.1s[CV 1/5; 3/120] START learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0\n",
      "[CV 1/5; 3/120] END learning_rate=0.001, loss=deviance, n_estimators=10, subsample=1.0;, score=0.829 total time=   0.5s\n",
      "[CV 5/5; 4/120] START learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5\n",
      "[CV 5/5; 4/120] END learning_rate=0.001, loss=deviance, n_estimators=50, subsample=0.5;, score=0.832 total time=   1.8s\n",
      "[CV 2/5; 7/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 7/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=0.5;, score=0.830 total time=   3.1s\n",
      "[CV 4/5; 9/120] START learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 9/120] END learning_rate=0.001, loss=deviance, n_estimators=100, subsample=1.0;, score=0.803 total time=   5.1s\n",
      "[CV 4/5; 11/120] START learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 11/120] END learning_rate=0.001, loss=deviance, n_estimators=500, subsample=0.75;, score=0.808 total time=  23.2s\n",
      "[CV 2/5; 18/120] START learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 18/120] END learning_rate=0.001, loss=exponential, n_estimators=50, subsample=1.0;, score=0.830 total time=   2.9s\n",
      "[CV 1/5; 20/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 20/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=0.75;, score=0.832 total time=   4.8s\n",
      "[CV 4/5; 21/120] START learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 21/120] END learning_rate=0.001, loss=exponential, n_estimators=100, subsample=1.0;, score=0.803 total time=   5.8s\n",
      "[CV 3/5; 23/120] START learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 23/120] END learning_rate=0.001, loss=exponential, n_estimators=500, subsample=0.75;, score=0.829 total time=  24.0s\n",
      "[CV 5/5; 29/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 5/5; 29/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=0.75;, score=0.831 total time=   1.9s\n",
      "[CV 4/5; 30/120] START learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 30/120] END learning_rate=0.01, loss=deviance, n_estimators=50, subsample=1.0;, score=0.808 total time=   3.3s\n",
      "[CV 1/5; 32/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75\n",
      "[CV 1/5; 32/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=0.75;, score=0.831 total time=   4.8s\n",
      "[CV 4/5; 33/120] START learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 33/120] END learning_rate=0.01, loss=deviance, n_estimators=100, subsample=1.0;, score=0.811 total time=   5.5s\n",
      "[CV 4/5; 35/120] START learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 4/5; 35/120] END learning_rate=0.01, loss=deviance, n_estimators=500, subsample=0.75;, score=0.825 total time=  23.5s\n",
      "[CV 2/5; 42/120] START learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 42/120] END learning_rate=0.01, loss=exponential, n_estimators=50, subsample=1.0;, score=0.836 total time=   2.6s\n",
      "[CV 4/5; 43/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 43/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=0.5;, score=0.808 total time=   3.8s\n",
      "[CV 4/5; 45/120] START learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 45/120] END learning_rate=0.01, loss=exponential, n_estimators=100, subsample=1.0;, score=0.812 total time=   5.5s\n",
      "[CV 2/5; 47/120] START learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 2/5; 47/120] END learning_rate=0.01, loss=exponential, n_estimators=500, subsample=0.75;, score=0.851 total time=  22.2s\n",
      "[CV 1/5; 53/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75\n",
      "[CV 1/5; 53/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=0.75;, score=0.859 total time=   2.3s\n",
      "[CV 1/5; 54/120] START learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 54/120] END learning_rate=0.1, loss=deviance, n_estimators=50, subsample=1.0;, score=0.857 total time=   2.8s\n",
      "[CV 3/5; 55/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 55/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=0.5;, score=0.863 total time=   4.1s\n",
      "[CV 2/5; 57/120] START learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 57/120] END learning_rate=0.1, loss=deviance, n_estimators=100, subsample=1.0;, score=0.863 total time=   6.0s\n",
      "[CV 1/5; 59/120] START learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 1/5; 59/120] END learning_rate=0.1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.879 total time=  20.6s\n",
      "[CV 4/5; 64/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5\n",
      "[CV 4/5; 64/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.5;, score=0.814 total time=   1.4s\n",
      "[CV 1/5; 65/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75\n",
      "[CV 1/5; 65/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=0.75;, score=0.852 total time=   2.0s\n",
      "[CV 2/5; 66/120] START learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 66/120] END learning_rate=0.1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.851 total time=   2.3s\n",
      "[CV 3/5; 67/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 67/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.851 total time=   2.7s\n",
      "[CV 5/5; 68/120] START learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75\n",
      "[CV 5/5; 68/120] END learning_rate=0.1, loss=exponential, n_estimators=100, subsample=0.75;, score=0.870 total time=   4.5s\n",
      "[CV 2/5; 70/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5\n",
      "[CV 2/5; 70/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=0.5;, score=0.884 total time=  13.8s\n",
      "[CV 3/5; 72/120] START learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0\n",
      "[CV 3/5; 72/120] END learning_rate=0.1, loss=exponential, n_estimators=500, subsample=1.0;, score=0.878 total time=  26.5s\n",
      "[CV 5/5; 83/120] START learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75\n",
      "[CV 5/5; 83/120] END learning_rate=1, loss=deviance, n_estimators=500, subsample=0.75;, score=0.856 total time=  22.3s\n",
      "[CV 1/5; 90/120] START learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 90/120] END learning_rate=1, loss=exponential, n_estimators=50, subsample=1.0;, score=0.867 total time=   2.6s\n",
      "[CV 3/5; 91/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 91/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=0.5;, score=0.862 total time=   3.9s\n",
      "[CV 3/5; 93/120] START learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 93/120] END learning_rate=1, loss=exponential, n_estimators=100, subsample=1.0;, score=0.887 total time=   5.8s\n",
      "[CV 3/5; 95/120] START learning_rate=1, loss=exponential, n_estimators=500, subsample=0.75\n",
      "[CV 3/5; 95/120] END learning_rate=1, loss=exponential, n_estimators=500, subsample=0.75;, score=0.895 total time=  24.6s\n",
      "[CV 2/5; 102/120] START learning_rate=2, loss=deviance, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 102/120] END learning_rate=2, loss=deviance, n_estimators=50, subsample=1.0;, score=0.844 total time=   2.5s\n",
      "[CV 3/5; 103/120] START learning_rate=2, loss=deviance, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 103/120] END learning_rate=2, loss=deviance, n_estimators=100, subsample=0.5;, score=0.641 total time=   2.9s\n",
      "[CV 1/5; 105/120] START learning_rate=2, loss=deviance, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 105/120] END learning_rate=2, loss=deviance, n_estimators=100, subsample=1.0;, score=0.802 total time=   5.2s\n",
      "[CV 5/5; 106/120] START learning_rate=2, loss=deviance, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 106/120] END learning_rate=2, loss=deviance, n_estimators=500, subsample=0.5;, score=0.248 total time=  16.3sCPU times: user 8.19 s, sys: 357 ms, total: 8.54 s\n",
      "Wall time: 6min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    \"loss\": [\"deviance\", \"exponential\"],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 1, 2],\n",
    "    \"n_estimators\": [10, 50, 100, 500],\n",
    "    \"subsample\": [0.5, 0.75, 1.0],\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(GradientBoostingClassifier(), params, n_jobs=-1, scoring='accuracy', verbose=10)\n",
    "  \n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "# Predict \n",
    "y_pred = gs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5ad5e24-2396-4ac2-83c4-0f31188248c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8966789667896679\n",
      "Test Precision: 0.9042105263157895\n",
      "Test Recall: 0.8910788381742739\n",
      "Test f1 Score: 0.8975966562173459\n",
      "Test roc auc score: 0.8967720021525174\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Test f1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Test roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0e3933b-738c-4180-af2e-95b10b6ee6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       933\n",
      "           1       0.90      0.89      0.90       964\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.90      0.90      0.90      1897\n",
      "weighted avg       0.90      0.90      0.90      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f4431dc-c563-47a8-b3e0-670c98ce43d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(y_pred, y_test, title=\"Gradient Boosting Classifier Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16e17f-78a2-4ec5-970f-32f775bbadc5",
   "metadata": {},
   "source": [
    "# Model 3: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a33153a4-84bc-4f96-a5a7-9997b4f8eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "# Fit model \n",
    "rf_model.fit(X_train, y_train)\n",
    "# Predict \n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f7a541c4-90ed-41a6-9300-bdc58a773dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [10, 50, 100, 200],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "gs_clf = GridSearchCV(RandomForestClassifier(), params, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "# Predict \n",
    "y_pred = gs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1bd442e5-089d-49eb-be7c-02d3cf59400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9182920400632578\n",
      "Test Precision: 0.9271383315733897\n",
      "Test Recall: 0.9107883817427386\n",
      "Test f1 Score: 0.9188906331763473\n",
      "Test roc auc score: 0.9184166989099545\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Test f1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Test roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dca79d09-51fb-4d2a-b754-ff11a7e43e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       933\n",
      "           1       0.93      0.91      0.92       964\n",
      "\n",
      "    accuracy                           0.92      1897\n",
      "   macro avg       0.92      0.92      0.92      1897\n",
      "weighted avg       0.92      0.92      0.92      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e35290f3-6c1a-40fe-b990-56e90dd4516f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAG5CAYAAACZTa6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2J0lEQVR4nO3debxd47nA8d+TSCSEEI0gxhK0VVQNUa2SoKUUrbFUuNrU7UCrblFUtajqqFSvoBVTqaqxqgil7TXWPFZqiphJIogh8dw/1jrsxBmTs885e6/fN5/1yRrevd537eHsZz/vu9aKzESSJKmR9evtBkiSJC0oAxpJktTwDGgkSVLDM6CRJEkNz4BGkiQ1PAMaSZLU8AxoNJeI+H5EnN3b7WgEEbFyRGRELFSn/X83Ik6rWd4xIqZExCsR8ZGIuC8iNqtH3W2057GI2KJO+/5ERDxUs7xGRNwZETMjYv+I+N+IOKIedXe3iBgRETeUbf/ZAuxnrte/UfX0+1TVZUDTAMovklnlF9kzEXFGRAzp7XYtiIjYLCLeLo+pZbqsB+vvVDASEatHxAUR8UJEzIiIuyPiwIjoX+82ZuaxmfmlmlU/Bb6emUMy847M/FBm/q276ouIxSPilxHxRPl6/Kdcfl931dGWzPx7Zq5Rs+o7wHWZuVhm/ioz98vMH3ZXfVHYPyLujYhXI+LJ8nX+cDfsfjzwArB4Zn57fnfSyuvfLSJi7/K9/4t51m9frj+jk/s5IyKO7qhcd79PpbYY0DSO7TJzCLAu8BHg0N5tTrd4qvxybpm26+oO6hlYRMSqwM3AFODDmTkU2BlYH1isXvW2YyXgvgXdSWtBXEQMBCYBHwI+DSwObAy8CGy4oHXOh7oda+kE4ABgf2AYsDpwMfCZBa2Tou33Z9++aul/gF3meX7GAf/urgrqlbmU2pSZTn18Ah4DtqhZPh74c83yIRR/oGYC9wM71mzbG/gHxa/7acCjwNY121cBri8fezVwEnB2zfbPUnyxTAf+Bnxgnnb9D3A38CpwOjAC+Eu5v2uAJds4ps2AJ9vY9oGyrull3Z+t2XYG8BvgirLOLYDlgAuB58vj27+m/IbAbcDLwLPAz8v1TwAJvFJOG7fSjrNrn+dWtq9c7mOhcnkf4IHy2B8BvlJT9n3A5eUxvQT8HehXbjsYmFo+7iFgbLn++2UbFi7bmOUx/2fe9wXFj5OW98GLwB+AYfO0c9/yuG9o5Vi+VD4/QzrzPiyf1xvL43m6fN8MLLcF8AvgufJ5vwdYq9y2DcV7dGZ5zAfN+34ArgXmAK+Xx716+bofXdOWbYE7y/r/D1h7nnYeTPG+fKPl9anZPqrc/4btHOtQ4EyK99TjwOE1r9fetPGZKtv5FvBm2fYtWmn7O8famde/C5/Fg8pjngGcDwxq49ha2n8l8Jly3TDgGeAnwBk1ZS8o188AbgA+VK4fP89xXtbWc8/c75srgJ/V7P884Le9+ffVqXmmXm+AUydepLn/ICxP8QVxQs32nSm+1PsBu1J86S1bbtu7/MPzZaA/8N/AU0CU228Efk7xpblp+Uf17HLb6uW+tgQGUHQDTObdL67HgJsogpiRFF9gt1NkkAZRfDEd2cYxzfVHvWb9gLKO7wIDgTFlm9Yot59R/nHdpDzeRYB/Ad8ry7+fIpj4VM3xfbGcHwKMLudXpiYYaaONzwD7tLN9rn1Q/LpfleIL/ZPAa8B65bYfAf9bHt8A4BNluTUoMkDL1exz1XL++8z9hZbAam28Lw4oX4vly9fyFOD387TzTGBRYHArx3IeMLEL78OPAqMpvrBWpgjkvllu+1T5mixRHuMHePf9+DTwiXJ+yZrnZ673A8UX9pdqls+gDAoo3l/PARtRvKfHlW1buKaddwIrtHGs+wGPd3CsZwKXUGTiVqbIXOzbyc/UO21tY/mdY+3s60/nPou3UPwdGFa+Hvu1cWx7UwQ0XwDOL9d9leI9czRzBzT/VT4HCwO/BO5s67jaeu6Z+32zTPnajQH2oPisLtZTf0udmnuyy6lxXBwRMyn++D0HHNmyITMvyMynMvPtzDwfeJi5uwkez8xTM3MOMBFYFhgRESsCGwBHZOYbmXkDUDuOZVeKDMXVmfkWxS/SwcDHasqcmJnPZuZUiqzDzVmM73gduIjiy6cty0XE9JppF4ovySHAcZn5ZmZeS5HZ2L3mcZdk5j8z823gw8DwzPxBWf4R4FRgt7LsW8BqEfG+zHwlM29q91me21IUX8Cdkpl/zsz/ZOF64CqKwKWlHcsCK2XmW1mMGUmKTMHCwAcjYkBmPpaZ/+lCG1vsBxyWmU9m5hsUX4Y7zZP2/35mvpqZs1p5fFeP9V+ZeVNmzs7Mxyi+DD9Zbn6L4ktwTYov+Qcy8+mabR+MiMUzc1pm3t6VgyyNB07JzJszc05mTqTIBoyuKfOrzJwyP8dadmPuBhyamTPL4/sZ8MWaYq1+pubjWDr7+nfms/ir8u/ASxSf43U7qPsiYLOIGArsRRHEzSUzf1s+By3vqXXK8u1p87nPzGcoAsCJFN1+e2XmzA72J3WKAU3j2CEzF6P4dbcmRRcGABGxV3lGyPSImA6sVbudItMAQGa+Vs4Oofg1Ny0zX60p+3jN/HK1y2UAMYUiG9Pi2Zr5Wa0stzd4+anMXKJm+kNZ55Syrto21dY5pWZ+JeYJjCiyOy1fLvtS/Lp9MCJujYht22nPvF6k+KLqlIjYOiJuioiXynZsw7uvw08oflFfFRGPRMQhAJk5GfgmxZfFcxFxXkQs14U2tlgJuKjmOXiA4suy9kt2SmsPLHX1WFePiMvLQeovA8dSHmsZhJ4E/JrimCZExOLlQz9P8bw8HhHXR8TGna2zxkrAt+d5zVegeO+0WJBjfR9FFqT2szDve7Ctz1SXdOH178xn8Zma+dc6ak8ZcPyZojttqcz8Z+32iOgfEceVg8Nfpsi0wNx/W1rT3nMPRbDVH3goM//RQVmp0wxoGkz5y/8Mil9oRMRKFBmJr1P8UVoCuJci1d+Rp4ElI2LRmnUr1sw/RfHlQVlXUHxxTJ3/I+jQU8AKEVH73lxxnjqzZn4K8Og8gdFimbkNQGY+nJm7A0sDPwb+WB5v7T7acg3FF3CHImJhinE8PwVGlK/DFZSvQ/kr99uZ+X6KsRAHRsTYctu5mflxiuc6y3Z21RSKcRy1z8OgMnPWor1jvgb41Dzvhfb8BngQGJWZi1MEke+857I4M+mjwAcpAsr/KdffmpnbU7weF1OM9emqKcAx8xzrIpn5+5oy7R3rJGD5iFi/je0vUGSSVqpZN+97sCtepegabbFM7cZOvv71+iyeCXybYqzWvL4AbE8xDmgoRXcYvPs6t/Ucd/TZOoYi4F42InbvoKzUaQY0jemXwJYRsQ7FmIikGLxIROxDkaHpUGY+TjFg9qiIGBgRHwdqzzT6A/CZiBgbEQMo/vC9QTEIs15upvh1+Z2IGBDF9Su2oxjj0ZpbgJkRcXBEDC5/Va4VERsARMSeETG8/EU7vXzM2xTP19sUY27aciTwsYj4SUQsU+5vtYg4OyKWmKfsQIqug+eB2RGxNbBVy8aI2LZ8bFCMAZoDvB3F9VbGlAHR6xRZrbfpuv8FjikDXCJieERs34XHn0URKFwYEWtGRL+IWCqKa6Fs00r5xSgG/L4SEWtSdCO0HOsGEbFR+Z55tTyut8v32B4RMbTsNnl5Po/1VGC/so6IiEUj4jMR0akzzzLzYeBk4PdRXD5gYEQMiojdIuKQshvpDxTP52Llc3ogrX/pd8adwDYRMax8H32zZUMXXv96fRavpxiXc2Ir2xYr63iRIiA7dp7tz9L+5+c9ImJTisHze1GMfToxIka2/yipcwxoGlBmPk/xy+p7mXk/Rf/+jRR/YD4M/LOdh8/rCxSDK1+i+AJ/px89Mx8C9qT4Y/cCRWCxXWa+2Q2H0apy39sBW5d1nkzRz/5gG+XnUJzxsi7F2SYvAKdR/KKE4hTk+yLiFYo++90yc1bZTXAM8M+y22J0K/v+D8WpyyuX+5hBkYW5jWKgcm3ZmRSnAP+B4syXLwCX1hQZRZEFeYXitTo5M6+jCIKOK9v9DEXmYn5OyT+hrO+qKMZa3UTxunZKOUZiC4qsy9UUwcYtFN0LN7fykIMojnEmRYBxfs22xct10yi6SV6k6HKDYhzKY2UXxn4UA0O7JDNvoxiQe1JZx2SKga5dsT/vdotNpzg7bEfeHUP2DYpg7BGKAbTnAr/taltLZwF3UXTZXMXcz1WnXv96fRbL8V6TynE38zqT4vWbSnFm2rzjz06nGPszPSIu7qiustvxTIprKU3NzL+X+/hdGehLC6RlVL4kSVLDMkMjSZIangGNJElqeAY0kiSp4RnQSJKkhtdnbx42eIMDHa0s9YLn//Gz3m6CVFlDFu7ZM74Gf+Tr3fZdO+uOk3r1bDUzNJIkqeH12QyNJEmqs2ievIYBjSRJVdVE1zRsntBMkiRVlhkaSZKqyi4nSZLU8OxykiRJ6jvM0EiSVFV2OUmSpIZnl5MkSVLfYYZGkqSqsstJkiQ1PLucJEmS+g4zNJIkVZVdTpIkqeHZ5SRJktR3mKGRJKmq7HKSJEkNzy4nSZKkvsMMjSRJVWWXkyRJanhNFNA0z5FIkqTKMkMjSVJV9WueQcEGNJIkVZVdTpIkSX2HGRpJkqqqia5DY0AjSVJV2eUkSZLUd5ihkSSpquxykiRJDa+JupwMaCRJqqomytA0T2gmSZIqywyNJElV1URdTs1zJJIkqWsium/qsKr4VkTcFxH3RsTvI2JQRKwSETdHxOSIOD8iBpZlFy6XJ5fbV+5o/wY0kiSpriJiJLA/sH5mrgX0B3YDfgz8IjNXA6YB+5YP2ReYVq7/RVmuXQY0kiRVVfTrvqljCwGDI2IhYBHgaWAM8Mdy+0Rgh3J++3KZcvvYiPbTQAY0kiRVVTd2OUXE+Ii4rWYa31JNZk4Ffgo8QRHIzAD+BUzPzNllsSeBkeX8SGBK+djZZfml2jsUBwVLkqQFlpkTgAmtbYuIJSmyLqsA04ELgE93Z/0GNJIkVVXPneW0BfBoZj4PEBF/AjYBloiIhcoszPLA1LL8VGAF4Mmyi2oo8GJ7FdjlJElSVfXcGJongNERsUg5FmYscD9wHbBTWWYccEk5f2m5TLn92szM9iowoJEkSXWVmTdTDO69HbiHIv6YABwMHBgRkynGyJxePuR0YKly/YHAIR3VYZeTJElV1YO3PsjMI4Ej51n9CLBhK2VfB3buyv4NaCRJqiqvFCxJktR3mKGRJKmqmuhu2wY0kiRVlV1OkiRJfYcZGkmSqsouJ0mS1Og6uN9jQ7HLSZIkNTwzNJIkVVQzZWgMaCRJqqrmiWfscpIkSY3PDI0kSRVll5MkSWp4zRTQ2OUkSZIanhkaSZIqqpkyNAY0kiRVVDMFNHY5SZKkhmeGRpKkqmqeBI0BjSRJVWWXkyRJUh9ihkaSpIpqpgyNAY0kSRXVTAGNXU6SJKnhmaGRJKmimilDY0AjSVJVNU88Y5eTJElqfGZoJEmqKLucJElSw2umgMYuJ0mS1PDM0EiSVFHNlKExoJEkqaqaJ56xy0mSJDU+MzSSJFWUXU6SJKnhNVNAY5eTJElqeGZoJEmqqGbK0BjQSJJUUc0U0NjlJEmSGp4BjSRJVRXdOLVXTcQaEXFnzfRyRHwzIoZFxNUR8XD5/5Jl+YiIX0XE5Ii4OyLW6+hQDGgkSaqoiOi2qT2Z+VBmrpuZ6wIfBV4DLgIOASZl5ihgUrkMsDUwqpzGA7/p6FgMaCRJUk8aC/wnMx8HtgcmlusnAjuU89sDZ2bhJmCJiFi2vZ0a0EiSVFHdmaGJiPERcVvNNL6NancDfl/Oj8jMp8v5Z4AR5fxIYErNY54s17XJs5wkSaqo7jzLKTMnABM6qG8g8Fng0FYenxGR81u/GRpJkqqqhwYF19gauD0zny2Xn23pSir/f65cPxVYoeZxy5fr2mRAI0mSesruvNvdBHApMK6cHwdcUrN+r/Jsp9HAjJquqVbVNaCJiNUjYlJE3Fsurx0Rh9ezTkmS1Dk9dZZTWdeiwJbAn2pWHwdsGREPA1uUywBXAI8Ak4FTga92tP96j6E5Ffgf4BSAzLw7Is4Fjq5zvZIkqQM9eaXgzHwVWGqedS9SnPU0b9kEvtaV/de7y2mRzLxlnnWz61ynJEmqmHpnaF6IiFWBBIiInYB2+8DUO76x+6bsvcNoMpP7Jj/N+B+cxxtvzh17fn6LdTjsy58igXv+/RR7H3H2AtW55OKLcNaxX2SlZYfx+NMvseehZzJ95ix2+/R6HLjXGCKCV157nf2Pu5B7Hn5qgeqSmtE5Z53BxX/6I0Gw2qhRHPnDHzFw4EBOPvGXXHP1lfTr15+ddtmN3ffYq7ebqj6qme7lVO+A5msUp3CtGRFTgUeBPepcp7poueFD+equn+Ajux7P62+8xdnH7sXOW32Esy+/9Z0yq67wPg7aeyxjvnQi02fOYviSQzq9/0+stypf3G4Dxh913lzrDxo3hr/d+jA/nXgtB40bw0HjxnL4SZfz2FMvsdVXfs30mbPY6mNr8uvv7sym+5zQbccrNYPnnn2W8845iwsu/jODBg3i4IO+yV+v/DNk8uwzz3DhJX+hX79+vPTii73dVPVhzRTQ1LvLacnM3AIYDqyZmR8HPlznOjUfFlqoH4MXHkD//v0YPGgATz8/Y67t/7XDaE654J9MnzkLgOenvfLOtm/tuTn/mPhNbjn3IA4f/6lO17ntJ9d6J2g6+/Jb2W6ztQC46e7H3qnnlnseZ+TSSyzIoUlNa86cObzxxuvMnj2b11+fxfDhS/PHP5zHl/f7Kv36FX/ehy21VAd7kZpDvQOaUyNircx8NTNnRsRuwBF1rlNd9NTzM/jl2X/j35cdwaN/+T4vv/o6k27+91xlRq04nFErDufa077B9b89gC03XhOAsRutzqorvo+Pj/slG+3xMz6y5vJs8pH3d6repYctxjMvzgTgmRdnsvSwxd5TZu/tN+Kv//fAAh6h1HyWHjGCPcf9F5/ZagyfGvsJhgxZjI0/9nGenPIEV135F/bc7fN847+/zBOPP9bbTVVf1vPXoambenc57QT8MSK+AHwC2AvYqq3C5WWSxwMstNJYFhq+dp2bJ4AlFhvMtpuuxQe2P5rpM2dx7nHj2G3rj3LeX/71Tpn+/fux2grD2eorv2bkiCW4ZsLXWH+3n7DF6DXYYqM1uOmcbwMwZPDCrLbCcP55xyPc8LsDGDhwIYYMXpglF1/knTKHn3g519z00HvaUQxqf9emH12NcZ/diLFfPrGORy81ppdfnsH1103isr9cw5DFFuPgg77JFZdfyptvvsXAhQdy9nkXcu01V3HU9w7j9Inn9HZz1Uc1U5dTXQOazHykzMpcDDwBbJWZs9op/85lkwdvcOB8X/5YXTNmw9V57KmXeGH6qwBcfN09jF575bkCmqnPzeDW+x5n9py3efypl3j4iedZbcXhRAQ/OWMSp19043v22zLupa0xNM+9NJNlliqyNMsstdhc3VhrrbYsvzl8F7Y/4FRemvFaPQ5bamg333QjI5dfniWHDQNgzNgtuevOO1h6xAjGjC1+N24+dku+/73v9mYzpR5Tly6niLgnIu6OiLuBPwLDgFWAm8t16kOmPDONDT+8EoMXHgDA5huM4qFHn52rzGXX38um660GwFJDF2XUisN5dOqLXH3jg4z77IYsOnggUAww7uyA4T/fcB97brsBAHtuuwGXX38vACuMWILzjt+HfY88l8lPPN8txyg1m2WWWZZ77r6LWbNmkZnccvONrPL+97PZmC247dabAfjXbbew0kor925D1af15IX16q1eGZpt67Rf1cGt9z3BRZPu4sazD2T2nLe566GpnH7RjRzxlU9z+wNT+PMN93H1jQ+yxUarc/v532HO28l3T7iMl2a8xqSb/82aq4zgb789AIBXX3uDfb53zlzZlrb8dOIkzv7RXoz77EY88cw09jz0TAAO/dJWDBu6CL88+PMAzJ79Nh8f94v6PQFSA/rw2uswdout2GPXz7FQ/4VY4wMf4HM77cobr7/OYYf+D+ecdQaLLLIIR3zf65iqbX0gDuk2Me+4hbpUErE0MKhlOTOf6OgxdjlJveP5f/yst5sgVdaQhXs2xFjtoL9023ft5J9u3avhUV3H0ETEZ4GfActR3EFzJeAB4EP1rFeSJHWsL3QVdZd6n7b9Q2A08O/MXIXifg031blOSZLUCRHdN/W2egc0b5U3nuoXEf0y8zpg/TrXKUmSKqbe16GZHhFDgBuAcyLiOeDVOtcpSZI6wS6nDkTEiuXs9sBrwLeAK4H/ANvVo05JktQ1zdTlVK8MzcXAepn5akRcmJmfBybWqS5JklRx9QpoamO1zt3YR5Ik9ah+/fpAaqWb1CugyTbmJUlSH9EXuoq6S70CmnUi4mWKTM3gcp5yOTNz8TrVK0mSKqguAU1m9q/HfiVJUvdpprOc6n3atiRJ6qOaKJ6p+4X1JEmS6s4MjSRJFWWXkyRJanjNFNDY5SRJkhqeGRpJkiqqiRI0BjSSJFWVXU6SJEl9iBkaSZIqqokSNAY0kiRVlV1OkiRJfYgZGkmSKqqJEjQGNJIkVZVdTpIkSX2IGRpJkiqqiRI0BjSSJFWVXU6SJEl9iBkaSZIqqokSNGZoJEmqqojotqkTdS0REX+MiAcj4oGI2DgihkXE1RHxcPn/kmXZiIhfRcTkiLg7ItbraP8GNJIkqSecAFyZmWsC6wAPAIcAkzJzFDCpXAbYGhhVTuOB33S0cwMaSZIqKqL7pvbriaHApsDpAJn5ZmZOB7YHJpbFJgI7lPPbA2dm4SZgiYhYtr06DGgkSaqo7uxyiojxEXFbzTS+pqpVgOeB30XEHRFxWkQsCozIzKfLMs8AI8r5kcCUmsc/Wa5rk4OCJUnSAsvMCcCENjYvBKwHfCMzb46IE3i3e6nl8RkROb/1m6GRJKmieqrLiSLD8mRm3lwu/5EiwHm2pSup/P+5cvtUYIWaxy9frmuTAY0kSRXVU2c5ZeYzwJSIWKNcNRa4H7gUGFeuGwdcUs5fCuxVnu00GphR0zXVKrucJElST/gGcE5EDAQeAfahSKz8ISL2BR4HdinLXgFsA0wGXivLtsuARpKkiurJWx9k5p3A+q1sGttK2QS+1pX9G9BIklRRXilYkiSpDzFDI0lSRTXT3bYNaCRJqqgmimcMaCRJqqpmytA4hkaSJDU8MzSSJFVUEyVoDGgkSaqqfk0U0djlJEmSGp4ZGkmSKqqJEjQGNJIkVZVnOUmSJPUhZmgkSaqofs2ToDGgkSSpquxykiRJ6kPM0EiSVFFNlKAxoJEkqaqC5olo7HKSJEkNzwyNJEkV5VlOkiSp4XmWkyRJUh9ihkaSpIpqogSNAY0kSVXVr4kiGrucJElSwzNDI0lSRTVRgsaARpKkqvIsJ0mSpD7EDI0kSRXVRAkaAxpJkqrKs5wkSZL6kDYzNBGxXnsPzMzbu785kiSppzRPfqb9LqeftbMtgTHd3BZJktSDmukspzYDmszcvCcbIkmSNL86HEMTEYtExOERMaFcHhUR29a/aZIkqZ76RfdNva0zg4J/B7wJfKxcngocXbcWSZKkHhER3Tb1ts4ENKtm5vHAWwCZ+RrNNY5IkiQ1uM5ch+bNiBhMMRCYiFgVeKOurZIkSXXXBxIr3aYzAc2RwJXAChFxDrAJsHc9GyVJkuqvL3QVdZcOA5rMvDoibgdGU3Q1HZCZL9S9ZZIkqWlExGPATGAOMDsz14+IYcD5wMrAY8AumTktikjrBGAb4DVg746uf9fZKwV/EhgLbA58ouuHIUmS+ppeOMtp88xcNzPXL5cPASZl5ihgUrkMsDUwqpzGA7/p8Fg6KhARJwP7AfcA9wJfiYhfd7rpkiSpT+oDZzltD0ws5ycCO9SsPzMLNwFLRMSy7e2oM2NoxgAfyMyWQcETgfvmp9WSJKk5RcR4imxKiwmZOaFmOYGrIiKBU8ptIzLz6XL7M8CIcn4kMKXmsU+W656mDZ0JaCYDKwKPl8srlOskSVID684hwWWAMqGdIh/PzKkRsTRwdUQ8OM/jswx25kt7N6e8jCKaWgx4ICJuKZc3Am6Z3wolSVLf0K8Hz3LKzKnl/89FxEXAhsCzEbFsZj5ddik9VxafSpFAabF8ua5N7WVofjr/zZYkSSpExKJAv8ycWc5vBfwAuBQYBxxX/n9J+ZBLga9HxHkUiZQZNV1TrWrv5pTXL/ghSJKkvqoHEzQjgIvKwcMLAedm5pURcSvwh4jYl2Joyy5l+SsoTtmeTHHa9j4dVdDhGJqIGA2cCHwAGAj0B17NzMW7fDiSJKnP6KkL62XmI8A6rax/keKyMPOuT+BrXamjM9ehOQnYHXgYGAx8CfC0bUmS1Gd06sJ6mTkZ6J+ZczLzd8Cn69ssSZJUbxHdN/W2zpy2/VpEDATujIjjKc4B7+wVhiVJUh/Vk2c51VtnApMvluW+DrxKcRrV5+rZKEmSpK7ozM0pWy6o9zpwFEBEnA/sWsd2SZKkOmuiBE2nupxas3G3tkKSJPW4njrLqSc4FkaSJDW89m59sF5bm4AB9WnOu6bd+PN6VyGpFUtu8PXeboJUWbPuOKlH62umrEZ7XU4/a2fbg+1skyRJDaCZupzau/XB5j3ZEEmSpPk1v4OCJUlSg+vXPAkaAxpJkqrKgEaSJDW8ZhpD0+EA5yjsGRHfK5dXjIgN6980SZKkzunMGVsnU1xIb/dyeSbebVuSpIbXL7pv6m2d6XLaKDPXi4g7ADJzWnmzSkmS1MCaqMepUxmatyKiP5AAETEceLuurZIkSeqCzmRofgVcBCwdEccAOwGH17VVkiSp7vo1UYqmM3fbPici/gWMpbjtwQ6Z+UDdWyZJkuqqKrc+AIqzmoDXgMtq12XmE/VsmCRJUmd1psvpzxTjZwIYBKwCPAR8qI7tkiRJddZEPU6d6nL6cO1yeRfur9atRZIkqUc00xiaLnefZebtwEZ1aIskSdJ86cwYmgNrFvsB6wFP1a1FkiSpRzRRgqZTY2gWq5mfTTGm5sL6NEeSJPWUvnCF3+7SbkBTXlBvscw8qIfaI0mS1GVtBjQRsVBmzo6ITXqyQZIkqWc006Dg9jI0t1CMl7kzIi4FLgBebdmYmX+qc9skSVIdNVE806kxNIOAF4ExvHs9mgQMaCRJUp/QXkCzdHmG0728G8i0yLq2SpIk1V1VBgX3B4YwdyDTwoBGkqQGF61+xTem9gKapzPzBz3WEkmSpPnUXkDTPGGbJEl6j6p0OY3tsVZIkqQe10wBTZv3csrMl3qyIZIkSfOrM6dtS5KkJhRNdCEaAxpJkiqqEl1OkiRJjcKARpKkiorovqlz9UX/iLgjIi4vl1eJiJsjYnJEnB8RA8v1C5fLk8vtK3e0bwMaSZIqql9Et02ddADwQM3yj4FfZOZqwDRg33L9vsC0cv0vynLtH0unj1qSJGk+RcTywGeA08rloLhP5B/LIhOBHcr57ctlyu1jo4MRzAY0kiRVVL/ovikixkfEbTXT+Hmq+yXwHeDtcnkpYHpmzi6XnwRGlvMjgSkA5fYZZfk2eZaTJEkV1Z1nbWfmBGBC6/XEtsBzmfmviNis+2p9lwGNJEmqt02Az0bENsAgYHHgBGCJiFiozMIsD0wty08FVgCejIiFgKHAi+1VYJeTJEkV1Y/otqk9mXloZi6fmSsDuwHXZuYewHXATmWxccAl5fyl5TLl9mszM9s/FkmSVEk9fdp2Kw4GDoyIyRRjZE4v158OLFWuPxA4pKMd2eUkSZJ6TGb+DfhbOf8IsGErZV4Hdu7Kfg1oJEmqqGa69YEBjSRJFdWFC+L1eY6hkSRJDc8MjSRJFdVECRoDGkmSqsouJ0mSpD7EDI0kSRXVRAkaAxpJkqqqmbppmulYJElSRZmhkSSpoqKJ+pwMaCRJqqjmCWfscpIkSU3ADI0kSRXVTNehMaCRJKmimiecsctJkiQ1ATM0kiRVVBP1OBnQSJJUVc102rZdTpIkqeGZoZEkqaKaKathQCNJUkU1U5eTAY0kSRXVPOFMc2WbJElSRZmhkSSpouxykiRJDa+Zumma6VgkSVJFmaGRJKmi7HKSJEkNr3nCGbucJElSEzBDI0lSRTVRj5MBjSRJVdWviTqd7HKSJEkNzwyNJEkVZZeTJElqeGGXkyRJUt9hhkaSpIqyy0mSJDU8z3KSJEnqQ8zQSJJUUc3U5WSGRpKkiorovqn9emJQRNwSEXdFxH0RcVS5fpWIuDkiJkfE+RExsFy/cLk8udy+ckfHYkAjSZLq7Q1gTGauA6wLfDoiRgM/Bn6RmasB04B9y/L7AtPK9b8oy7XLgEaSpIqKbvzXniy8Ui4OKKcExgB/LNdPBHYo57cvlym3j41oPw9kQCNJUkX1i+6bImJ8RNxWM42vrSsi+kfEncBzwNXAf4DpmTm7LPIkMLKcHwlMASi3zwCWau9YHBQsSZIWWGZOACa0s30OsG5ELAFcBKzZnfWboZEkqaJ6qsupVmZOB64DNgaWiIiW5MrywNRyfiqwAkC5fSjwYnv7NaCRJKmievAsp+FlZoaIGAxsCTxAEdjsVBYbB1xSzl9aLlNuvzYzs7067HKSJEn1tiwwMSL6UyRT/pCZl0fE/cB5EXE0cAdweln+dOCsiJgMvATs1lEFBjSSJFVUT91tOzPvBj7SyvpHgA1bWf86sHNX6qhLQBMRJ1KcjtWqzNy/HvVKkqTO69dEVwquV4bmtjrtV5Ik6T3qEtBk5sSOS0mSpN7UU11OPaGuY2giYjhwMPBBYFDL+swcU896JUlSx5rp5pT1HhR8DnA+8BlgP4pTsJ6vc53qYS+//DJHfe9wJk/+NxHBUT88lkGDBnP0D47ktddeY7nlRvKj43/KkCFDerupUp/zjT02Z+8dP0Zmct/kpxh/5Nm88ebsd7avsMySnPqDLzJ0scH079ePI068hL/+4/4FqnOl5ZbirOP2YdjQRbnjgSf4r8PP5K3Zc9h/zzHsvePGzJ79Ni9Me4X9jjqbJ56etqCHKPWIel+HZqnMPB14KzOvz8z/orhvg5rI8T86hk0+/gkuufxKLrjwElZ5/6oc9b3DOOBb3+bCiy9jzBZbcMZvT+vtZkp9znLDh/LV3T/JJnscz/o7H0v/fv3Y+VMfnavMwV/6NBdefTsb7/5j9jr0d5xw6K6d3v+e223EYV/Z5j3rjzlge0485zrW2v4ops2cxd47bgzAnQ9OYZM9jmfDXX/ERZPu4JgDdlig41PfF9049bZ6BzRvlf8/HRGfiYiPAMPqXKd60MyZM/nXv25lx88X10UaMHAgiy++OI8//hgfXX8DADbeeBMmXX1VbzZT6rMW6t+fwQsPoH//fgweNJCnn58x1/bMZPFFix77oUMGv7O9X7/g2G/uwD/O/h9uOf9Q9v38Jp2u85MbrM6frrkDgHMuu5ntNlsHgBtue5hZrxd/tm+5+zFGjlhiQQ9PfVy/iG6belu9u5yOjoihwLeBE4HFgW/VuU71oKlPPsmSSw7je4cdykMPPcgHP/QhvnPIYay62iiuu3YSY8ZuwVV/vZJnnnm6t5sq9TlPPT+DX545iX//5YfMeuNNJt34IJNuenCuMseccgWXnfx1/nu3T7LI4IX5zH4nArD3Dh9jxiuz+PieP2HggIW49owDuebGB3n8qXavDs9SSyzKjJmzmDPnbQCmPjuN5ZYe+p5ye++wMX/954J1bUk9qa4BTWZeXs7OADbvqHx5Z87xACedfAr7fnl8B49Qb5szZzYPPnA/hxx2BGuvvQ4//tHR/Pa0CRz1w2M47kfHMOF/T2azzccwYMDA3m6q1Ocssdhgtt3sw3xg2yOZPvM1zj1+X3bbZgPOu+LWd8rs8un1OfuymzjhrGvZaO1VOP3ovfjoTseyxcZrstaokey4RXGtsqFDBrHaisOZ+errXHHKNwAYtvgiDBiwENttvjYA+x5+Js+8MOO9DZnHbttswHofXJEtv3RCHY5afUnv51W6T73Pclod+A0wIjPXioi1gc9m5tGtla+9U+frs9u+MJ/6jhEjlmHEiGVYe+0iZb3lVp/mt6dN4Ov7f5NTTv0tAI899ig3XP+3Xmyl1DeN2WhNHnvqRV6Y9goAF197F6PXWWWugGbcDhuz/dd+DcDNdz/KoIEDeN8SixIRHPjjC7jmxgfes9/Rux0HFGNoVlpuKY455Yq5tg9dbDD9+/djzpy3GTliSZ567t0gZ/ON1uDgfT/FVl/6JW++NRs1uSaKaOo9huZU4FDKsTTlpY87vB+DGsf7hg9nxDLL8NijjwBw80038v5VV+XFF4u099tvv82pp/yGnXf1ZZfmNeWZl9jww6sweNAAADbfcA0eevTZ95TZbMM1AFhjlREMWngAz097hav/7wHG7/xxFlqo+DO+2opLs8igzmVCb7jt33yuzOzssd1GXP63uwFYZ43lOemw3djpW6fwfBlkSY2i3mNoFsnMW2LuwUKG/E3mkO8ewaEHH8Rbb73F8suvwA+O/hGXXXox5/3+XADGbrElO+z4+V5updT33Hrv41x0zR3ceO7BzJ7zNnc9+CSnX/hPjvjvz3D7/U/w5+vv4ZCfX8TJR+zON/bcnEz48vfOAuB3F/0fKy03jBvPPYQIeGHaK+xy4IRO1XvYCZdw1nH7cORXt+Wuh6ZwxsU3AnDst3Zg0UUW5pzj9wVgyjPT2Pmbp9Tn4NUnNNOF9aKDu3Ev2M4j/gJ8HbggM9eLiJ2AfTNz644ea5eT1DuW3ODrvd0EqbJm3XFSj0YYtzwyo9u+azd8/9BejY7qnaH5GsWYmDUjYirwKLBHneuUJEkVU++znB4BtoiIRSnG67xGMYbm8XrWK0mSOtY8HU51GhQcEYtHxKERcVJEbEkRyIwDJgO71KNOSZLURU10qeB6ZWjOAqYBNwJfBg6jONwdM/POOtUpSZIqql4Bzfsz88MAEXEa8DSwYma+Xqf6JElSFzXTWU71Cmha7uFEZs6JiCcNZiRJ6lv6wC2Yuk29App1IuLlcj6AweVyAJmZi9epXkmSVEF1CWgys3899itJkrpPEyVo6n4dGkmS1Fc1UURT73s5SZIk1Z0ZGkmSKsqznCRJUsNrprOc7HKSJEkNzwyNJEkV1UQJGgMaSZIqq4kiGgMaSZIqqpkGBTuGRpIkNTwzNJIkVVQzneVkQCNJUkU1UTxjl5MkSWp8ZmgkSaqqJkrRGNBIklRRnuUkSZLUh5ihkSSpojzLSZIkNbwmimfscpIkSfUVEStExHURcX9E3BcRB5Trh0XE1RHxcPn/kuX6iIhfRcTkiLg7ItbrqA4DGkmSqiq6cWrfbODbmflBYDTwtYj4IHAIMCkzRwGTymWArYFR5TQe+E1HFRjQSJJUUdGN/9qTmU9n5u3l/EzgAWAksD0wsSw2EdihnN8eODMLNwFLRMSy7dVhQCNJkhZYRIyPiNtqpvFtlFsZ+AhwMzAiM58uNz0DjCjnRwJTah72ZLmuTQ4KliSporrzLKfMnABMaL++GAJcCHwzM1+OmgZkZkZEzm/9ZmgkSaqonhtCAxExgCKYOScz/1SufralK6n8/7ly/VRghZqHL1+ua5MBjSRJqqsoUjGnAw9k5s9rNl0KjCvnxwGX1KzfqzzbaTQwo6ZrqlV2OUmSVFU9dyGaTYAvAvdExJ3luu8CxwF/iIh9gceBXcptVwDbAJOB14B9OqrAgEaSpIrqqXs5ZeY/aDt8GttK+QS+1pU67HKSJEkNzwyNJEkV5b2cJElSw2uieMYuJ0mS1PjM0EiSVFVNlKIxoJEkqaJ66iynnmCXkyRJanhmaCRJqijPcpIkSQ2vieIZu5wkSVLjM0MjSVJVNVGKxoBGkqSK8iwnSZKkPsQMjSRJFeVZTpIkqeE1UTxjl5MkSWp8ZmgkSaoou5wkSVITaJ6Ixi4nSZLU8MzQSJJUUXY5SZKkhtdE8YxdTpIkqfGZoZEkqaLscpIkSQ3PezlJkiT1IWZoJEmqquZJ0BjQSJJUVU0Uz9jlJEmSGp8ZGkmSKsqznCRJUsPzLCdJkqQ+xAyNJElV1TwJGgMaSZKqqoniGbucJElS4zNDI0lSRXmWkyRJanjNdJaTAY0kSRXVTBkax9BIkqSGZ0AjSZLqLiJ+GxHPRcS9NeuGRcTVEfFw+f+S5fqIiF9FxOSIuDsi1uto/wY0kiRVVET3TZ1wBvDpedYdAkzKzFHApHIZYGtgVDmNB37T0c4NaCRJUt1l5g3AS/Os3h6YWM5PBHaoWX9mFm4CloiIZdvbvwGNJEkVFd35L2J8RNxWM43vRBNGZObT5fwzwIhyfiQwpabck+W6NnmWkyRJFdWdZzll5gRgwgI8PiMi5/fxZmgkSVJvebalK6n8/7ly/VRghZpyy5fr2mRAI0lSRUU3TvPpUmBcOT8OuKRm/V7l2U6jgRk1XVOtsstJkqSq6sEL60XE74HNgPdFxJPAkcBxwB8iYl/gcWCXsvgVwDbAZOA1YJ+O9m9AI0mS6i4zd29j09hWyibwta7s34BGkqSK8l5OkiSp4XkvJ0mSpD7EDI0kSRXVRAkaAxpJkiqriSIau5wkSVLDM0MjSVJFeZaTJElqeJ7lJEmS1IdEcTE+qXtFxPjyzquSepCfPVWVGRrVy/jeboBUUX72VEkGNJIkqeEZ0EiSpIZnQKN6sQ9f6h1+9lRJDgqWJEkNzwyNJElqeAY0kiSp4RnQqEsiYk5E3FkzrdxGuZUj4t4ebp7UtGo+e/dGxGURscR87mfviDipm5sn9ToDGnXVrMxct2Z6rLcbJFVEy2dvLeAl4Gu93SCpLzGg0QKJiCERMSkibo+IeyJi+1bKvD8i7oiIDSJi1Yi4MiL+FRF/j4g1e6PdUoO7ERgJ0NZnKiK2i4iby8/eNRExoldbLNWZN6dUVw2OiDvL+UeBnYEdM/PliHgfcFNEXNpSOCLWAM4D9s7MuyJiErBfZj4cERsBJwNjevYQpMYVEf2BscDp5aoJtP6Z+gcwOjMzIr4EfAf4dm+0WeoJBjTqqlmZuW7LQkQMAI6NiE2Btyl+Nbb8EhwOXAJ8LjPvj4ghwMeAC+LdW7wu3FMNlxpcy4+JkcADwNUdfKaWB86PiGWBgRQ/QKSmZUCjBbUHReDy0cx8KyIeAwaV22YATwAfB+6n6OKcXhsQSeq0WZm5bkQsAvyVYgzNGbT9mToR+HlmXhoRmwHf75lmSr3DMTRaUEOB58pgZnNgpZptbwI7AntFxBcy82Xg0YjYGSAK6/R8k6XGlZmvAftTdB+9RtufqaHA1HJ+XI83VOphBjRaUOcA60fEPcBewIO1GzPzVWBb4FsR8VmKjM6+EXEXcB/wnkHEktqXmXcAdwO70/Zn6vsUXVH/Al7ojXZKPclbH0iSpIZnhkaSJDU8AxpJktTwDGgkSVLDM6CRJEkNz4BGkiQ1PAMaqRfNcwflC8qLps3vvs6IiJ3K+dMi4oPtlN0sIj42H3U8Vt7iolPr29hHl+/23JX9S6omAxqpd9XeQflNYL/ajRExX1fzzswvZeb97RTZjOKS+ZLUFAxopL7j78BqZfbk7+VNPu+PiP4R8ZOIuDUi7o6Ir8A7V4U9KSIeiohrgKVbdhQRf4uI9cv5T5d3Q7+rvDP6yhSB07fK7NAnImJ4RFxY1nFrRGxSPnapiLgqIu6LiNOAoJMiYsOIuLG82/P/lTcqbbFC2caHI+LImsfsGRG3lO06pbwRoyR1yHs5SX1AmYnZGriyXLUesFZmPhoR44EZmblBRCwM/DMirgI+AqwBfJDihqD3A7+dZ7/DgVOBTct9DcvMlyLif4FXMvOnZblzgV9k5j8iYkWKewV9ADgS+Edm/iAiPgPs24XDehD4RGbOjogtgGOBz5fbNgTWorh0/60R8WfgVWBXYJPyVhonU1wF98wu1CmpogxopN7VcgdlKDI0p1N0Bd2SmS13R94KWLtlfAzFPXpGAZsCv8/MOcBTEXFtK/sfDdzQsq/MfKmNdmwBfLDmjs2Ll3dy3hT4XPnYP0fEtC4c21BgYkSMAhIYULPt6sx8ESAi/kRxA9PZwEcpAhyAwcBzXahPUoUZ0Ei9a9a8d0ouv8xfrV0FfCMz/zpPuW26sR39gNGZ+XorbZlfPwSuy8wdy26uv9Vsm/eeK0lxnBMz89AFqVRSNTmGRur7/gr8d0QMAIiI1SNiUeAGYNdyjM2ywOatPPYmYNOIWKV87LBy/UxgsZpyVwHfaFmIiHXL2RuAL5TrtgaW7EK7a+/2vPc827aMiGERMRjYAfgnMAnYKSKWbmlrRKyEJHWCAY3U951GMT7m9oi4FziFIrt6EfBwue1M4MZ5H5iZzwPjgT+Vd2M+v9x0GbBjy6BgYH+Ku6bfHRH38+7ZVkdRBET3UXQ9PdFOO++OiCfL6efA8cCPIuIO3psNvgW4kOKO0Rdm5m3lWVmHA1dFxN3A1cCynXyOJFWcd9uWJEkNzwyNJElqeAY0kiSp4RnQSJKkhmdAI0mSGp4BjSRJangGNJIkqeEZ0EiSpIb3/7MH5x+zrpM8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_matrix(y_pred, y_test, title=\"Random Forest Classifier Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f1ab9-2987-44cc-8606-8a4bcfbb731b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
